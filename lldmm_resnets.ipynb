{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "import pymeshlab\n",
    "import polyscope as ps\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLDDM Resnets using L2 Loss\n",
    "\n",
    "This is code for using the LLDDM with an L2 loss.\n",
    "\n",
    "When using this, ensure that the order of points in the point cloud of the start and target image are correctly matched. \n",
    "\n",
    "Ie, if you want to register a point cloud hand, you need to know where exactly a point of that hand ends up in the target image, and retain the order of counting points when describing input/output as vectors.\n",
    "\n",
    "If this isn't doable, use Chamfer's distance instead, implemented lower down in this code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseEulerFBlock(tf.keras.Model):\n",
    "    \"\"\"A Dense neural network block (n+relu x n x 2).\n",
    "\n",
    "    The LLDDM paper considers a resnet where each residual passthrough occurs after 3 dense blocks.\n",
    "    The size parameters effect how the net learns in an intuitive manner. \n",
    "\n",
    "    The first layer learns a partitioning of the input space into distinct polyhedra. \n",
    "    Relu is what allows for the hard boundary between cells.\n",
    "    \n",
    "    The second layer learns the contribution of each polyhedra.\n",
    "\n",
    "    The third layer learns vectors with contributions from the above.\n",
    "    For use with 2D registrations set this to 2. With 3D, 3, and so on.\n",
    "\n",
    "    With this, it can be seen that each block learns tangent vectors within each\n",
    "    polyhedra, with respect to contributions from other polyhedra.\n",
    "    \"\"\"\n",
    "    def __init__(self, widths):\n",
    "        super(DenseEulerFBlock, self).__init__()\n",
    "        self.initialiser = tf.keras.initializers.HeNormal()\n",
    "        \n",
    "        self.d1 = tf.keras.layers.Dense(widths[0], activation='relu')\n",
    "        self.d2 = tf.keras.layers.Dense(widths[1], activation=None)\n",
    "        self.d3 = tf.keras.layers.Dense(widths[2], activation=None, use_bias=False)\n",
    "        \n",
    "    def call(self, input_tensor, training=False):\n",
    "        return self.d3(self.d2(self.d1(input_tensor)))\n",
    "\n",
    "\n",
    "class DenseEulerMergeBlock(tf.keras.Model):\n",
    "    \"\"\"This is just a RELU block.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(DenseEulerMergeBlock, self).__init__()\n",
    "        \n",
    "    def call(self, input_tensor, training=False):\n",
    "        return tf.nn.relu(input_tensor)\n",
    "\n",
    "\n",
    "def DenseCombinedLoss(d1, d2, d3, d4, d5, d6, m6, truth, sigma=0.1):\n",
    "    \"\"\" The loss function: Kinetic energy minisation subject to correct registration.\n",
    "\n",
    "    Args:\n",
    "        d_{i = 1, ..., 6} : The outputs of each DenseEulerFBlock in the net.\n",
    "                            I end up using 6 blocks, hence 6 of these exist.\n",
    "        m6 : The final net output.\n",
    "        truth : The expected output.\n",
    "        sigma (float, optional): A regularisation parameter determining the ratio of significant\n",
    "                                 of correct registration and kinetic energy minimisation. \n",
    "                                 Defaults to 0.1.\n",
    "    \"\"\"\n",
    "    regularisation_loss = 0.5*(tf.norm(d1) + tf.norm(d2) + tf.norm(d3) + tf.norm(d4) + tf.norm(d5) + tf.norm(d6))/6\n",
    "    data_term           = 0.5*tf.norm(m6-truth)/sigma\n",
    "    return regularisation_loss + data_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "initializer = tf.keras.initializers.HeNormal()\n",
    "\n",
    "input0 = tf.keras.Input(shape=(1, 2))\n",
    "\n",
    "d1 = DenseEulerFBlock((500,500,2))(input0)\n",
    "m1 = DenseEulerMergeBlock()(input0 + d1)\n",
    "\n",
    "d2 = DenseEulerFBlock((500,500,2))(m1)\n",
    "m2 = DenseEulerMergeBlock()(m1 + d2)\n",
    "\n",
    "d3 = DenseEulerFBlock((500,500,2))(m2)\n",
    "m3 = DenseEulerMergeBlock()(m2 + d3)\n",
    "\n",
    "d4 = DenseEulerFBlock((500,500,2))(m3)\n",
    "m4 = DenseEulerMergeBlock()(m3 + d4)\n",
    "\n",
    "d5 = DenseEulerFBlock((500,500,2))(m4)\n",
    "m5 = DenseEulerMergeBlock()(m4 + d5)\n",
    "\n",
    "d6 = DenseEulerFBlock((500,500,2))(m5)\n",
    "m6 = DenseEulerMergeBlock()(m5 + d6)\n",
    "\n",
    "\n",
    "true0 = tf.keras.Input(shape=(1, 2))\n",
    "model = tf.keras.Model([input0, true0], [input0, m1, m2, m3, m4, m5, m6, true0])\n",
    "model.add_loss(DenseCombinedLoss(d1, d2, d3, d4, d5, d6, m6, true0, sigma=0.1))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4,beta_1=0.9,beta_2=0.999, epsilon=1e-07)\n",
    "model.compile(optimizer=opt, loss=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLDDM Resnets using Chamfer's Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chamfers_distance(y_pred, y_true):\n",
    "       \"\"\"Computes Chamfer's distance between two 3D point clouds.\n",
    "       \"\"\"\n",
    "       cd1 =  tf.math.reduce_sum(tf.math.sqrt(\n",
    "              tf.math.reduce_min(tf.math.reduce_sum(\n",
    "              tf.math.square(tf.reshape(y_pred, (batch_size, 1, 1, 3)) - y_true), axis=-1), axis=1)))\n",
    "       cd2 =  tf.math.reduce_sum(tf.math.sqrt(\n",
    "              tf.math.reduce_min(tf.math.reduce_sum(\n",
    "              tf.math.square(tf.reshape(y_true, (batch_size, 1, 1, 3)) - y_pred), axis=-1), axis=1)))\n",
    "       return cd1 + cd2\n",
    "\n",
    "\n",
    "def DenseCombinedCDLoss(d1, d2, d3, d4, d5, d6, m6, truth, sigma=0.1):\n",
    "    regularisation_loss = 0.5*(tf.norm(d1) + tf.norm(d2) + tf.norm(d3) + tf.norm(d4) + tf.norm(d5) + tf.norm(d6))/6\n",
    "    data_term = 0.5*chamfers_distance(m6, truth)/(sigma**2)\n",
    "    return data_term + regularisation_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_obj_to_numpy(obj):\n",
    "    \"\"\"Convert .obj to .npy object. For use with SCHREC19 objects.\n",
    "    \"\"\"\n",
    "    ms = pymeshlab.MeshSet()\n",
    "    ms.load_new_mesh(obj)\n",
    "    m = ms.current_mesh()\n",
    "    v_matrix = m.vertex_matrix()\n",
    "    return v_matrix\n",
    "\n",
    "\n",
    "def collect_source_and_target(sourcefile, targetfile):\n",
    "    \"\"\"Loads and returns normalised sourcefile.obj and \n",
    "       targetfile.obj objects as numpy arrays.\n",
    "    \"\"\"\n",
    "    source_shape  = convert_obj_to_numpy(sourcefile)\n",
    "    target_shape  = convert_obj_to_numpy(targetfile)\n",
    "\n",
    "    source_shape = source_shape.reshape((source_shape.shape[0], 1, 3))\n",
    "    target_shape = target_shape.reshape((target_shape.shape[0], 1, 3))\n",
    "\n",
    "    source_scaling = np.max(source_shape)\n",
    "    source_bias    = np.min(source_shape)\n",
    "    source_shape   = (source_shape - np.min(source_shape))/np.max(source_shape)\n",
    "    source_shape   = (source_shape - np.min(source_shape))/np.max(source_shape)\n",
    "\n",
    "    target_scaling = np.max(target_shape)\n",
    "    target_bias    = np.min(target_shape)\n",
    "    target_shape   = (target_shape - np.min(target_shape))/np.max(target_shape)\n",
    "    target_shape   = (target_shape - np.min(target_shape))/np.max(target_shape)\n",
    "\n",
    "    source_shape = tf.convert_to_tensor(source_shape)\n",
    "    target_shape = tf.convert_to_tensor(target_shape)\n",
    "    \n",
    "    return source_shape, target_shape\n",
    "\n",
    "\n",
    "source_shape, target_shape = collect_source_and_target('scan_015.obj', 'scan_016.obj')\n",
    "batch_size=source_shape.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "input0 = tf.keras.Input(shape=(1, 3))\n",
    "\n",
    "d1 = DenseEulerFBlock((800,800,3))(input0)\n",
    "m1 = DenseEulerMergeBlock()(input0 + d1)\n",
    "\n",
    "d2 = DenseEulerFBlock((800,800,3))(m1)\n",
    "m2 = DenseEulerMergeBlock()(m1 + d2)\n",
    "\n",
    "d3 = DenseEulerFBlock((800,800,3))(m2)\n",
    "m3 = DenseEulerMergeBlock()(m2 + d3)\n",
    "\n",
    "d4 = DenseEulerFBlock((800,800,3))(m3)\n",
    "m4 = DenseEulerMergeBlock()(m3 + d4)\n",
    "\n",
    "d5 = DenseEulerFBlock((800,800,3))(m4)\n",
    "m5 = DenseEulerMergeBlock()(m4 + d5)\n",
    "\n",
    "d6 = DenseEulerFBlock((800,800,3))(m5)\n",
    "m6 = DenseEulerMergeBlock()(m5 + d6)\n",
    "\n",
    "\n",
    "true0 = tf.keras.Input(shape=(1, 3))\n",
    "model = tf.keras.Model([input0, true0], [input0, m1, m2, m3, m4, m5, m6, true0])\n",
    "model.add_loss(DenseCombinedCDLoss(d1, d2, d3, d4, d5, d6, m6, true0, sigma=0.1))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=5e-6,beta_1=0.9,beta_2=0.999, epsilon=1e-07)\n",
    "model.compile(optimizer=opt, loss=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - running the net\n",
    "model.fit(x=[source_shape, target_shape], y=None, epochs=1000, verbose=1, batch_size=batch_size);\n",
    "plt.plot(model.history.history['loss']);\n",
    "print(model.history.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flow reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_numpy_to_points_and_vertices(np_arr):\n",
    "    \"\"\"Constructs vertices and faces from a numpy array of points.\n",
    "    \"\"\"\n",
    "    ms = pymeshlab.Mesh(np_arr)\n",
    "    ms.generate_surface_reconstruction_ball_pivoting()\n",
    "    m = ms.current_mesh()\n",
    "    v_matrix = m.vertex_matrix()\n",
    "    f_matrix = m.face_matrix()\n",
    "    return [v_matrix, f_matrix]\n",
    "\n",
    "\n",
    "def make_pointed_flow(model, source_shape, target_shape, separator=50):\n",
    "    \"\"\"Constructs a numpy array characteristing the time-series \n",
    "       flow of source to target shape according to a trained LDDMM resnet.\n",
    "    \"\"\"\n",
    "    prediction = model.predict([source_shape, target_shape])\n",
    "    prediction[0] = prediction[0].reshape((prediction[0].shape[0], 3))\n",
    "    full_flow = np.copy(prediction[0]*100)\n",
    "    for i in range(1, len(prediction)):\n",
    "        prediction[i] = prediction[i].reshape((prediction[i].shape[0], 3))\n",
    "        full_flow = np.append(full_flow, prediction[i]*100 + i*separator*np.array([1, 0, 0]), axis=0)\n",
    "    return full_flow\n",
    "\n",
    "\n",
    "def visualise_flow(point_cloud, pts_per_obj=None, view_style='turntable', mesh_type='ball', mesh=True):\n",
    "    \"\"\"Visualise the network's generated point cloud flow using polyscope and open3d libraries.\n",
    "    \"\"\"\n",
    "    ps.init()\n",
    "    ps.set_navigation_style(view_style)\n",
    "    if mesh is not True:\n",
    "        # visualise non-meshed flow (just a point-cloud)  \n",
    "        ps.register_point_cloud(\"pointed_flow\", point_cloud)\n",
    "\n",
    "    elif mesh is True:\n",
    "        if pts_per_obj is None:\n",
    "            raise ValueError(\"As you are meshing, you need to specify `pts_per_obj`. Generally this is point_cloud.shape[0]/(resnet_lddmm timesteps + 2)\")\n",
    "            \n",
    "        for i in range(point_cloud.shape[0]//pts_per_obj):\n",
    "            # visualising it meshed\n",
    "            obj = point_cloud[pts_per_obj*i:pts_per_obj*(i+1)]\n",
    "\n",
    "            # import points into the open3d 03d object\n",
    "            pcd = o3d.geometry.PointCloud()\n",
    "            pcd.points = o3d.utility.Vector3dVector(obj)\n",
    "            pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=5, max_nn=100)) # estimates normals for the point cloud\n",
    "            \n",
    "            if mesh_type == 'ball':\n",
    "                radius = np.mean(pcd.compute_nearest_neighbor_distance())\n",
    "                meshes = o3d.geometry.TriangleMesh.create_from_point_cloud_ball_pivoting(pcd,o3d.utility.DoubleVector([radius, radius]))\n",
    "            \n",
    "            elif mesh_type == 'poisson':\n",
    "                # computes the smooth poisson mesh of the point cloud\n",
    "                meshes = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=11, width=0, scale=1.5, linear_fit=True)[0]\n",
    "            \n",
    "            elif mesh_type == 'alpha':\n",
    "                alpha_val = 0.1 # adjust as necessary\n",
    "                meshes = o3d.geometry.TriangleMesh.create_from_point_cloud_alpha_shape(pcd, alpha_val)\n",
    "\n",
    "            # write mesh to .obj file, which will then be viewed by pymeshlab and then polyscope\n",
    "            o3d.io.write_triangle_mesh(\"full_flow_meshed_pivoted\" + \"{}\".format(i) + \".obj\", meshes)\n",
    "\n",
    "            # create pymeshlab object that will then have states and properties stored\n",
    "            ms = pymeshlab.MeshSet()\n",
    "            ms.load_new_mesh('full_flow_meshed_pivoted' + '{}'.format(i) + '.obj')\n",
    "            m = ms.current_mesh()\n",
    "\n",
    "            # get numpy arrays of vertices and faces of the current mesh\n",
    "            v_matrix = m.vertex_matrix()\n",
    "            f_matrix = m.face_matrix()\n",
    "\n",
    "            # visualise with polyscope\n",
    "            # a=ps.register_point_cloud(\"full_flow_rasterised {}\".format(i), v_matrix)\n",
    "            b=ps.register_surface_mesh(\"full_flow_meshed {}\".format(i), v_matrix, f_matrix, smooth_shade=True)\n",
    "            b.set_back_face_policy('identical')\n",
    "    ps.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning the model and visualising its flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('full_flow', visualise_flow(model, source_shape, target_shape))\n",
    "# point_cloud = np.load('full_flow.npy')\n",
    "# visualise_flow(point_cloud, 1001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('meshnets')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12a1d7a2830ebf6b599b36fc598e0959b2d2ea8030417450915ea9a54428d7d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
